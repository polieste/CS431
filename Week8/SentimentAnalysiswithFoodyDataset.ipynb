{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3X4f6raKjwm"
      },
      "source": [
        "# Phân tích cảm xúc với LSTMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRT94Ow0KzFw",
        "outputId": "a3d1ee07-d281-49e3-d63b-e45d873c6c9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBId3VkcK313",
        "outputId": "effd0ddd-984e-491c-a250-ed020d51557d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CS431/assignment3-master\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/CS431/assignment3-master"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "id": "H2o4m1G8n1S5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f4af05-9b11-42b2-b6c4-54b755c0667e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1ODbyyWKjwq",
        "outputId": "a065d8c6-e0a2-4c88-edbf-80138ad71015"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Simplified vocabulary loaded!\n",
            "Word embedding matrix loaded!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "currentDir = '/content/drive/MyDrive/CS431/assignment3-master'\n",
        "\n",
        "wordsList = np.load(os.path.join(currentDir, 'wordsList.npy'))\n",
        "#wordsList = np.load('wordslist.npy')\n",
        "print('Simplified vocabulary loaded!')\n",
        "wordsList = wordsList.tolist()\n",
        "#wordsList = [word.decode('UTF-8') for word in wordsList] #Encode words as UTF-8\n",
        "wordVectors = np.load(os.path.join(currentDir, 'wordVectors.npy'))\n",
        "#wordVectors = np.load('wordVectors.npy')\n",
        "wordVectors = np.float32(wordVectors)\n",
        "print ('Word embedding matrix loaded!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_Q78kclKjwr"
      },
      "source": [
        "Để chắc chắn mọi dữ liệu được load lên một cách chính xác, chúng ta cần kiểm tra xem số lượng từ trong từ điển rút gọn và số chiều của ma trận word embedding có khớp với nhau hay không? Trong trường hợp này số từ mà chúng tôi giữ lại là 19,899 và số chiều trong không gian biểu diễn là 300 chiều."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUY3i4tSKjwr",
        "outputId": "20f1356b-3255-4449-a9db-ee463d338e9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the vocabulary:  19899\n",
            "Size of the word embedding matrix:  (19899, 300)\n"
          ]
        }
      ],
      "source": [
        "print('Size of the vocabulary: ', len(wordsList))\n",
        "print('Size of the word embedding matrix: ', wordVectors.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwXLNoCWKjws"
      },
      "source": [
        "## Word2Vec trên một từ đơn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqMol3JgKjws"
      },
      "source": [
        "Để có thể xác định được vector biểu diễn của một từ tiếng Việt. Đầu tiên chúng ta sẽ xác định xem vị trí của từ đó trong wordsList. Sau đó lấy vector ở dòng tương ứng trên trên ma trận wordVectors. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuMUhyneKjws",
        "outputId": "7ca039c9-90cc-425b-efa4-2d313b7ce09e",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of `ngon` in wordsList:  14598\n",
            "Vector representation of `ngon` is:  [-2.040e-02 -9.800e-03  2.290e-01 -3.770e-02  5.430e-02 -2.680e-02\n",
            "  2.190e-02 -6.290e-02 -2.200e-02 -1.010e-02  8.300e-03 -8.810e-02\n",
            " -3.630e-02  7.820e-02 -7.780e-02 -4.930e-02 -6.600e-03 -1.026e-01\n",
            " -1.040e-02  5.380e-02  4.100e-02  6.530e-02 -2.770e-02 -6.340e-02\n",
            "  2.270e-02  4.420e-02  3.340e-02 -4.960e-02  8.290e-02 -3.990e-02\n",
            "  3.750e-02  1.800e-02 -1.115e-01 -7.200e-02 -5.060e-02 -1.051e-01\n",
            " -4.560e-02 -1.765e-01 -3.300e-02 -6.800e-03  5.580e-02 -4.180e-02\n",
            "  4.380e-02  4.940e-02  7.400e-03  4.020e-02 -8.850e-02 -9.840e-02\n",
            " -5.210e-02 -5.500e-03  3.730e-02 -8.460e-02 -6.910e-02 -4.980e-02\n",
            " -3.910e-02 -4.980e-02 -8.690e-02  6.100e-03 -5.360e-02 -3.800e-03\n",
            "  1.162e-01 -4.160e-02  5.000e-03 -7.240e-02 -3.320e-02  1.800e-02\n",
            "  1.200e-02 -4.420e-02  1.350e-01  6.580e-02 -1.110e-02  1.960e-02\n",
            "  1.750e-02  2.010e-02  2.200e-03  1.810e-01 -6.610e-02 -6.860e-02\n",
            " -4.690e-02  7.890e-02  6.880e-02 -5.320e-02  2.770e-02  5.710e-02\n",
            " -1.183e-01  4.170e-02 -8.200e-02 -5.900e-02  8.790e-02  9.640e-02\n",
            "  6.000e-02  1.330e-02 -3.640e-02 -1.110e-02 -2.200e-02  1.770e-02\n",
            " -3.420e-02 -4.020e-02  3.590e-02  1.467e-01 -1.730e-02 -2.650e-02\n",
            "  6.400e-02  7.000e-03 -3.930e-02 -5.540e-02 -4.360e-02  8.000e-02\n",
            " -5.480e-02  3.840e-02 -8.330e-02  7.070e-02 -9.100e-03  2.480e-02\n",
            " -7.500e-03  3.030e-02 -6.600e-03 -9.800e-03  7.640e-02 -9.300e-03\n",
            "  2.330e-02 -2.000e-02  5.970e-02 -2.680e-02 -2.000e-02 -9.700e-03\n",
            " -5.310e-02 -9.820e-02 -2.570e-02  2.400e-02 -5.860e-02  1.820e-02\n",
            " -4.280e-02  9.580e-02  3.400e-02 -7.100e-03 -6.200e-03  1.239e-01\n",
            "  4.830e-02 -4.050e-02  4.810e-02 -1.093e-01  1.540e-02 -3.860e-02\n",
            "  1.250e-01 -7.950e-02  6.800e-03  7.420e-02  5.500e-02 -4.130e-02\n",
            " -2.090e-02 -2.250e-02  3.960e-02 -1.086e-01 -2.200e-02 -4.420e-02\n",
            "  1.965e-01 -2.260e-02  1.196e-01  1.200e-02  1.199e-01 -8.700e-03\n",
            "  4.260e-02  3.460e-02 -3.780e-02  1.951e-01 -9.300e-03 -6.260e-02\n",
            "  2.730e-02  7.340e-02  1.800e-03  5.080e-02 -3.470e-02 -9.680e-02\n",
            " -1.278e-01  3.790e-02  6.920e-02 -5.300e-02 -1.020e-01  1.076e-01\n",
            "  1.361e-01 -7.390e-02  9.650e-02 -2.250e-02  1.597e-01 -2.750e-02\n",
            " -4.200e-03  1.032e-01 -4.910e-02 -7.100e-03 -1.840e-02  7.240e-02\n",
            " -2.040e-02 -5.010e-02 -2.000e-04 -4.190e-02 -5.720e-02 -8.000e-03\n",
            "  9.780e-02 -7.130e-02 -6.070e-02 -1.740e-02 -1.290e-02  8.250e-02\n",
            "  6.600e-03 -2.250e-02 -5.100e-02  6.520e-02 -1.870e-02  5.790e-02\n",
            "  1.814e-01 -1.220e-01  4.770e-02  5.300e-02 -4.230e-02  2.139e-01\n",
            " -9.100e-03  1.314e-01 -3.600e-02 -3.780e-02  4.260e-02  3.000e-04\n",
            " -8.200e-02  1.570e-02 -1.380e-02  3.420e-02 -2.080e-02  1.790e-01\n",
            "  5.240e-02 -1.464e-01  6.330e-02  5.620e-02  2.000e-03 -6.490e-02\n",
            "  4.000e-04 -1.310e-02  1.020e-02  6.380e-02 -1.190e-02  2.440e-02\n",
            " -1.430e-02  1.027e-01  3.200e-03 -1.120e-02  8.270e-02  5.690e-02\n",
            "  2.740e-02 -9.800e-02 -3.150e-02 -9.750e-02 -1.660e-02  7.640e-02\n",
            " -4.960e-02 -7.940e-02  1.177e-01 -2.800e-03  6.860e-02 -5.930e-02\n",
            "  7.470e-02  5.790e-02  3.450e-02  5.550e-02 -3.380e-02  1.292e-01\n",
            "  3.840e-02  7.440e-02 -6.450e-02  2.470e-02 -1.810e-02  9.840e-02\n",
            " -1.329e-01 -6.380e-02 -8.360e-02 -3.580e-02  6.500e-03  8.240e-02\n",
            " -6.140e-02 -1.116e-01  2.310e-02  8.070e-02 -1.670e-02  4.150e-02\n",
            " -8.210e-02  6.290e-02 -5.580e-02  2.600e-03 -2.170e-02  3.200e-03\n",
            " -5.500e-03  6.040e-02  2.990e-02 -1.061e-01  5.200e-02  7.560e-02\n",
            "  6.250e-02  1.007e-01 -1.080e-01 -5.420e-02 -6.620e-02  6.080e-02]\n"
          ]
        }
      ],
      "source": [
        "ngon_idx = wordsList.index('ngon')\n",
        "print('Index of `ngon` in wordsList: ', ngon_idx)\n",
        "ngon_vec = wordVectors[ngon_idx]\n",
        "print('Vector representation of `ngon` is: ', ngon_vec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYGzb9j9Kjwu"
      },
      "source": [
        "### ToDo 3.1: Word2Vec để biểu diễn một đoạn văn bản"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-10zVt8QKjwu"
      },
      "source": [
        "Nâng cấp hơn so với phiên bản Word2Vec cho từ đơn, phần này chúng ta sẽ biểu diễn một câu dưới dạng một ma trận gồm các vector biểu diễn của từng từ chồng lên nhau.\n",
        "\n",
        "Ví dụ như chúng ta muốn biểu diễn câu \"Món này ăn hoài không biết chán\". Đầu tiên, với mỗi từ trong câu ta sẽ tìm chỉ số tương ứng trong từ điển và lưu vào vector đặt tên là 'sentenceIndexes'. Sau đó, chúng ta có thể sử dụng hàm tra cứu ma trận word embedding của thư viện Tensorflow tf.nn.embedding_lookup để tra các vector tại các chỉ số trong 'sentenceIndexes'. Như vậy nếu chúng ta sử dụng tối đa 10 từ để lưu trữ cho một câu thì ma trận biểu diễn cho câu sẽ là một ma trận kích thước 10 x 300."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sys9jhu8Kjwu"
      },
      "source": [
        "![caption](Images/embedding.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMRy8G3FKjwu",
        "outputId": "7c6cd7cb-d47f-48f0-c835-0a2381a9df71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: activate: command not found\n"
          ]
        }
      ],
      "source": [
        "!activate tf-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zZwJHHKuKjwu",
        "outputId": "6926339c-2491-4d4b-de62-9e0c906117a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10,)\n",
            "Row index for each word:  [  119  8136  4884 18791 16614 15951  3371     0     0     0]\n",
            "Sentence representation of word vectors:\n",
            "(10, 300)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "maxSeqLength = 10   #Maximum length of sentence\n",
        "numDimensions = 300 #Dimensions for each word vector\n",
        "sentenceIndexes = np.zeros((maxSeqLength), dtype='int32')\n",
        "\n",
        "# TODO 3.1: Gán chỉ số của các từ trong câu và 'sentenceIndexes'\n",
        "sentenceIndexes[0] = wordsList.index('món')\n",
        "sentenceIndexes[1] = wordsList.index('này')\n",
        "sentenceIndexes[2] = wordsList.index('ăn')\n",
        "sentenceIndexes[3] = wordsList.index('hoài')\n",
        "sentenceIndexes[4] = wordsList.index('không')\n",
        "sentenceIndexes[5] = wordsList.index('biết')\n",
        "sentenceIndexes[6] = wordsList.index('chán')\n",
        "\n",
        "# Các chỉ số 7, 8, 9 của sentenceIndexes  vẫn được gán bằng 0 như cũ\n",
        "print(sentenceIndexes.shape)\n",
        "print('Row index for each word: ', sentenceIndexes)\n",
        "\n",
        "# Ma trận biểu diễn:\n",
        "print('Sentence representation of word vectors:')\n",
        "with tf.Session() as sess:\n",
        "    print(tf.nn.embedding_lookup(wordVectors,sentenceIndexes).eval().shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL3HeMX5Kjwv"
      },
      "source": [
        "Nếu như thực hiện đúng thì vector 'sentenceIndexes' sẽ có giá trị là: [119, 8136, 4884, 18791, 16614, 15951, 3371, 0, 0, 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IO97NamBKjwv"
      },
      "source": [
        "# 2. Khảo sát tập dữ liệu huấn luyện và tạo ma trận ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIPaxtjiKjwv",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f896fc5-40f5-40a3-ef1c-c038b4d04995"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive files finished\n",
            "Negative files finished\n",
            "The total number of files is 30000\n",
            "The total number of words in the files is 1770824\n",
            "The average number of words in the files is 59.02746666666667\n"
          ]
        }
      ],
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "positiveFiles = ['positiveReviews/' + f for f in listdir('positiveReviews/') if isfile(join('positiveReviews/', f))]\n",
        "negativeFiles = ['negativeReviews/' + f for f in listdir('negativeReviews/') if isfile(join('negativeReviews/', f))]\n",
        "numWords = []\n",
        "for pf in positiveFiles:\n",
        "    with open(pf, \"r\", encoding='utf-8') as f:\n",
        "        line=f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)       \n",
        "print('Positive files finished')\n",
        "\n",
        "for nf in negativeFiles:\n",
        "    with open(nf, \"r\", encoding='utf-8') as f:\n",
        "        line=f.readline()\n",
        "        counter = len(line.split())\n",
        "        numWords.append(counter)  \n",
        "print('Negative files finished')\n",
        "\n",
        "numFiles = len(numWords)\n",
        "print('The total number of files is', numFiles)\n",
        "print('The total number of words in the files is', sum(numWords))\n",
        "print('The average number of words in the files is', sum(numWords)/len(numWords))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0jBv50fPKjww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "45f2558d-9745-4144-804b-a55d1e873450"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.hist(numWords, 50)\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.axis([0, 1200, 0, 8000])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kfs2aEIqKjww"
      },
      "outputs": [],
      "source": [
        "maxSeqLength = 180"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3pg994JKjww"
      },
      "source": [
        "Để có cảm nhận rõ hơn về dữ liệu, chúng ta có thể hiển thị một số review bất kỳ như sau."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utYIdn_DKjww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d70fde9-eb28-4e4b-e2d9-513e6981f486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A positive sentence: \n",
            "Buổi_trưa Leng_Keng không đông , lác_đác vài bàn nên các bạn phục_vụ rất nhanh , mình đi dạo 1 vòng vì rất ấn_tượng những bảng_hiệu của quán . Không_chỉ bảng_hiệu mà đến wc cũng rất dễ_thương , tò_mò quá , không biết bên wc nữ thì thế_nào nhỉ ? Có bạn nữ nào update dùm mình để mở_mang tầm_mắt không : v\n",
            "\n",
            "Tụi mình có chọn vài món nướng do các bạn phục_vụ có giới_thiệu , không biết phải trúng món tủ của Leng_Keng không nhưng đậm_đà vừa_miệng , trưa lai_rai thêm mấy lon Tiger , mấy anh_em ngồi chém gió khá thoải_mái ( đến tận gần 3h chiều ) . Phục_vụ lâu nhưng thái_độ của các bạn PV rất thiện_chí : ) ) , hay do mình say nên thấy vậy nhi ?\n",
            "\n",
            "Nghe_nói Leng_Keng buổi tối đông , hôm nào đi thử vì thấy không_gian của quán mùa này ngồi hàn_huyên chắc tuyệt lắm .\n",
            "\n",
            "A negative sentence: \n",
            "Quán này dc cái là k gian trên tầng đẹp nhưng nhân_viên còn khá chậm . Thêm một điều là họ vẫn chưa hiểu hết khách order gì , khi tôi yêu_cầu một phần Chocolate bạc_hà , không đường nhiều bạc_hà , có thạch thì lại mang cho tôi một ly đầy vị ngọt thêm chân trâu > cần cải_thiện trong khâu này\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print('A positive sentence: ')\n",
        "fname = positiveFiles[3] # Randomly select a positive file to view\n",
        "with open(fname, encoding='utf-8') as f:\n",
        "    for lines in f:\n",
        "        print(lines)\n",
        "\n",
        "print('A negative sentence: ')\n",
        "fname = negativeFiles[10] # Randomly select a negative file to view\n",
        "with open(fname, encoding='utf-8') as f:\n",
        "    for lines in f:\n",
        "        print(lines)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtGq9-ohKjwx"
      },
      "source": [
        "## Chuẩn hoá văn bản và tách từ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1y3DcBLKjwx"
      },
      "outputs": [],
      "source": [
        "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
        "import re\n",
        "strip_special_chars = re.compile(\"[^\\w0-9 ]+\")\n",
        "\n",
        "def cleanSentences(string):\n",
        "    string = string.lower().replace(\"<br />\", \" \")\n",
        "    return re.sub(strip_special_chars, \"\", string.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgOfemC9Kjwx"
      },
      "source": [
        "### ToDo 3.2: xác định chỉ số của từng từ trong review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBONV8QXKjwx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124e23f1-2c95-425d-a6b4-0255df762b2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive files are indexed!\n",
            "Negative files are indexed!\n"
          ]
        }
      ],
      "source": [
        "ids = np.zeros((numFiles, maxSeqLength), dtype='int32')\n",
        "nFiles = 0\n",
        "# Index of Unknow word\n",
        "unk_idx = wordsList.index('UNK')\n",
        "\n",
        "for pf in positiveFiles:\n",
        "    with open(pf, \"r\", encoding=\"utf-8\") as f:\n",
        "        nIndexes = 0\n",
        "        line=f.readline()\n",
        "        cleanedLine = cleanSentences(line)\n",
        "        split = cleanedLine.split()\n",
        "        for word in split:\n",
        "            # TODO 3.2: Nếu 'word' thuộc tập 'wordsList' thì gán chỉ số của 'word' vào ma trận ids\n",
        "            try:\n",
        "                ids[nFiles][nIndexes] = wordsList.index(word)\n",
        "            # Ngược lại: gán 'unk_idx' vào ma trận ids\n",
        "            except:\n",
        "                ids[nFiles][nIndexes] = unk_idx\n",
        "            \n",
        "            nIndexes = nIndexes + 1\n",
        "            if nIndexes >= maxSeqLength:\n",
        "                break\n",
        "        nFiles = nFiles + 1 \n",
        "\n",
        "print('Positive files are indexed!')\n",
        "for nf in negativeFiles:\n",
        "    with open(nf, \"r\", encoding=\"utf-8\") as f:\n",
        "        nIndexes = 0\n",
        "        line=f.readline()\n",
        "        cleanedLine = cleanSentences(line)\n",
        "        split = cleanedLine.split()\n",
        "        for word in split:\n",
        "            # ToDo 3.2: tương tự như trên. Không khác gì hết.\n",
        "            try:\n",
        "                ids[nFiles][nIndexes] = wordsList.index(word)\n",
        "            except:\n",
        "                ids[nFiles][nIndexes] = unk_idx\n",
        "                \n",
        "            nIndexes = nIndexes + 1\n",
        "            if nIndexes >= maxSeqLength:\n",
        "                break\n",
        "        nFiles = nFiles + 1 \n",
        "\n",
        "print('Negative files are indexed!')\n",
        "# Save ids Matrix for future uses.\n",
        "#np.save(os.path.join(currentDir,'idsMatrix.npy'), ids)\n",
        "np.save('idsMatrix.npy',ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jiLRsOfKjwy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285ba00a-13f8-4c7b-91f7-3483554d764a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word indexes of the first review:  [ 7446 11694 11440 11975  8136 18109 15221  9051 18101 11975 18313  7080\n",
            " 11975 15993 10610 18109  2876 10642  4756 15570  2331 11440  4826 10231\n",
            "  1346   255  9071  4935  6263   255 13800  6874   557 15522  4826  1046\n",
            "  1528 16601  9071  7456 14855 19492  1346  9649 13800   624 11154  3902\n",
            "  1868 11417  2986  5175 16760 10642  6287 15570  2682 10642 14598 13969\n",
            "  9887  9071  3553   251 15240   877  8333  9572  7352  9572 13145  5244\n",
            " 15522  1131  4884 11417  5416  7352  5175  6874  4756  9334  3364  4826\n",
            "  9051  4884 17511 12225 18941 10138 16235 17162  6915  2750 10642 19193\n",
            " 15522 12778 11975 14595  2374  2997 15570 18160 13952  5767  6874  7255\n",
            "  2876 14597     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
          ]
        }
      ],
      "source": [
        "# LƯU Ý: Bước thực hiện trên tương đối mất thời gian.\n",
        "# Trường hợp đã tính toán và lưu ma trận 'ids' rồi thì ta có thể load lên để sử dụng luôn\n",
        "ids = np.load(os.path.join(currentDir,'idsMatrix.npy'))\n",
        "#ids = np.load('idsMatrix.npy')\n",
        "print('Word indexes of the first review: ', ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP1Wg-d2Kjwy"
      },
      "source": [
        "Nếu như quá trình chuyển từ câu dạng văn bảng sang vector các chỉ số trong từ điển ở trên đúng thì ids[0] sẽ nhận giá trị: [19898  1906  4454  5284 10661 11694 11994 18784 18569 18619 13174  9821 ...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY2QPOpNKjwy"
      },
      "source": [
        "## Xây dựng hàm lấy dữ liệu train và test theo từng batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hvM_P_IKjwy"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "\n",
        "def getTrainBatch():\n",
        "    labels = []\n",
        "    arr = np.zeros([batchSize, maxSeqLength])\n",
        "    for i in range(batchSize):\n",
        "        if (i % 2 == 0): \n",
        "            # Pick positive samples randomly\n",
        "            num = randint(1,13999)\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            # Pick negative samples randomly\n",
        "            num = randint(15999,29999)\n",
        "            labels.append([0,1])\n",
        "        arr[i] = ids[num-1:num]\n",
        "    return arr, labels\n",
        "\n",
        "def getTestBatch():\n",
        "    labels = []\n",
        "    arr = np.zeros([batchSize, maxSeqLength])\n",
        "    for i in range(batchSize):\n",
        "        num = randint(13999,15999)\n",
        "        if (num <= 14999):\n",
        "            labels.append([1,0])\n",
        "        else:\n",
        "            labels.append([0,1])\n",
        "        arr[i] = ids[num-1:num]\n",
        "    return arr, labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r0fIEm3Kjwy"
      },
      "source": [
        "# 3. Xây dựng RNN Model với Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1ytu0abKjwz"
      },
      "outputs": [],
      "source": [
        "# Initialize paramters\n",
        "numDimensions = 300\n",
        "batchSize = 64\n",
        "lstmUnits = 128\n",
        "nLayers = 2\n",
        "numClasses = 2\n",
        "iterations = 5000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P928x1VVKjwz"
      },
      "source": [
        "![caption](Images/data_batch.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cnkpi1cKjwz"
      },
      "source": [
        "## ToDo 3.3: Xác định input và output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.disable_eager_execution()"
      ],
      "metadata": {
        "id": "zhfFBN-ogzMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31B-PsnGKjwz"
      },
      "outputs": [],
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "# TODO 3.3: Khởi tạo hai biến 'inputs' và 'labels'\n",
        "inputs = tf.placeholder(tf.int32, [batchSize,maxSeqLength])\n",
        "labels = tf.placeholder(tf.float32,[batchSize,numClasses])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfMS7-eFKjw0"
      },
      "source": [
        "![caption](Images/embedding_data.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_OLcnzqKjw0"
      },
      "outputs": [],
      "source": [
        "data = tf.nn.embedding_lookup(wordVectors, inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9lRd3vV5Kjw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e0d42b-d760-4f12-8319-e170666dc867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-94a3de3536b8>:3: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  lstmLayer = tf.nn.rnn_cell.BasicLSTMCell(lstmUnits)\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-21-94a3de3536b8>:14: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/layers/rnn/legacy_cells.py:726: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"rnn/transpose_1:0\", shape=(64, 180, 128), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "def generate_a_lstm_layer():\n",
        "    # Khởi tạo một LSTM layer với 'lstmUnits' unit sử dụng hàm tf.contrib.rnn.BasicLSTMCell\n",
        "    lstmLayer = tf.nn.rnn_cell.BasicLSTMCell(lstmUnits)\n",
        "    # Sau đó tạo một lớp dropout để chống overfitting với hệ số out_keep_prob bằng 0.75\n",
        "    # Sử dụng hàm tf.contrib.rnn.DropoutWrapper\n",
        "    lstmLayer = tf.nn.rnn_cell.DropoutWrapper(cell=lstmLayer, output_keep_prob=0.75)\n",
        "    return lstmLayer\n",
        "\n",
        "# Sau khi đã có hàm tạo một LSTM Layer, ta sử dụng hàm này để chồng các LSTM lên\n",
        "# Stack các LSTM layer với hàm tf.nn.rnn_cell.MultiRNNCell\n",
        "lstmLayers = tf.nn.rnn_cell.MultiRNNCell([generate_a_lstm_layer() for i in range(nLayers)], state_is_tuple=True)\n",
        "# Feed data variable vào mạng LSTM sử dụng hàm tf.nn.dynamic_rnn\n",
        "initial_state = lstmLayers.zero_state(batchSize, tf.float32)\n",
        "outputs, _ = tf.nn.dynamic_rnn(lstmLayers,data,dtype=tf.float32,initial_state=initial_state)\n",
        "print(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSH1aQLXKjw2"
      },
      "source": [
        "Sau khi ra khỏi mạng LSTM, biến outputs sẽ là một tensor có kích thước [batchSize x maxSeqLength x lstmUnits], cụ thể là [64 x 180 x 128]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kP9EzL2Kjw3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d8c970-f4d3-428a-d275-6fb7d607a2db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'add:0' shape=(64, 2) dtype=float32>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "weight = tf.Variable(tf.random.truncated_normal([lstmUnits, numClasses]))\n",
        "bias = tf.Variable(tf.constant(0.1, shape=[numClasses]))\n",
        "\n",
        "# Lấy giá trị output tại LSTM cell cuối cùng\n",
        "outputs = tf.transpose(outputs, [1, 0, 2])\n",
        "last = tf.gather(outputs, int(outputs.get_shape()[2]) - 1)\n",
        "# Đưa qua mạng Fully Connected mà không có activation function\n",
        "prediction = (tf.matmul(last, weight) + bias)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB3TAnmNKjw4"
      },
      "outputs": [],
      "source": [
        "correctResult = tf.equal(tf.argmax(prediction,1), tf.argmax(labels,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correctResult, tf.float32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WabPJ1w2Kjw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ac3d717-6540-4532-a1b7-fc2a245c9b31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=labels))\n",
        "optimizer = tf.train.AdamOptimizer().minimize(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "It3tsMpgKjw5"
      },
      "source": [
        "# 4. Huấn luyện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJBkHA9eKjw5"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "\n",
        "tf.summary.scalar('Loss', loss)\n",
        "tf.summary.scalar('Accuracy', accuracy)\n",
        "merged = tf.summary.merge_all()\n",
        "logdir = \"/content/drive/MyDrive/CS431/assignment3-master/tensorboard\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONTPt6juKjw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "465fca44-2fb7-4c6b-9ff1-c03f7e37ee65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved to /content/drive/MyDrive/CS431/assignment3-master/models/pretrained_lstm.ckpt-2000\n",
            "saved to /content/drive/MyDrive/CS431/assignment3-master/models/pretrained_lstm.ckpt-4000\n"
          ]
        }
      ],
      "source": [
        "sess = tf.InteractiveSession()\n",
        "writer = tf.summary.FileWriter(logdir, sess.graph)\n",
        "saver = tf.train.Saver()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "for i in range(iterations):\n",
        "    # TODO 3.5\n",
        "    # Get next training batch\n",
        "    nextBatch, nextBatchLabels = getTrainBatch()\n",
        "    # Feed to optimizer\n",
        "    sess.run(optimizer, {inputs:nextBatch,labels:nextBatchLabels})\n",
        "    #Write summary to Tensorboard\n",
        "    if (i % 50 == 0):\n",
        "        summary = sess.run(merged, {inputs: nextBatch, labels: nextBatchLabels})\n",
        "        writer.add_summary(summary, i)\n",
        "\n",
        "    # Save model every 2000 training iterations\n",
        "    if (i % 2000 == 0 and i != 0):\n",
        "        save_path = saver.save(sess, os.path.join(currentDir,\"/content/drive/MyDrive/CS431/assignment3-master/models/pretrained_lstm.ckpt\"), global_step=i)\n",
        "        print(\"saved to %s\" % save_path)\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HosYe4oyKjw6"
      },
      "source": [
        "# 5. Load mô hình đã train và đánh giá mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOOtqVlEKjw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57951ea-c9a5-438f-a381-89021d40ca10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py:1768: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ]
        }
      ],
      "source": [
        "sess = tf.InteractiveSession()\n",
        "saver = tf.train.Saver()\n",
        "#saver.restore(sess, tf.train.latest_checkpoint(os.path.join(currentDir,'models')))\n",
        "saver.restore(sess, tf.train.latest_checkpoint('/content/drive/MyDrive/CS431/assignment3-master/models'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFy3OwUkKjw6"
      },
      "source": [
        "### ToDo 3.6: Test mô hình"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oA3BAXyVKjw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2728cccc-4b98-412a-a1a6-b3735d339696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for this batch: 0.8125\n",
            "Accuracy for this batch: 0.828125\n",
            "Accuracy for this batch: 0.796875\n",
            "Accuracy for this batch: 0.765625\n",
            "Accuracy for this batch: 0.765625\n",
            "Accuracy for this batch: 0.71875\n",
            "Accuracy for this batch: 0.78125\n",
            "Accuracy for this batch: 0.71875\n",
            "Accuracy for this batch: 0.734375\n",
            "Accuracy for this batch: 0.734375\n"
          ]
        }
      ],
      "source": [
        "# Test on 10 batches\n",
        "iterations = 10\n",
        "for i in range(iterations):\n",
        "    nextBatch, nextBatchLabels = getTestBatch()\n",
        "    # TODO 3.6: Tính độ chính xác 'accuracy' trên các test batch và gán vào 'test_acc'\n",
        "    test_acc = sess.run(accuracy,feed_dict={inputs:nextBatch,labels:nextBatchLabels})\n",
        "    print(\"Accuracy for this batch:\", test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CfXWuL4Kjw7"
      },
      "source": [
        "Do các bộ test được lấy ngẫu nhiên nên độ chính xác trong quá trình này cũng dao động từ 70% đến 90%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkT-tiguKjw7"
      },
      "source": [
        "## ToDo 3.7: Viết hàm tổng hợp để dự đoán cảm xúc từ câu tiếng Việt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6v11sC6Kjw7"
      },
      "outputs": [],
      "source": [
        "input_sentence = 'Món này ăn ngon mê ly luôn. Vị ngọt và thơm quá trời quá đất.'\n",
        "# TODO 3.7 Các bạn vận dụng toàn bộ quy trình đã thực hiện trước đó\n",
        "# để dự đoán xem câu này có cảm xúc tích cực hay tiêu cực\n",
        "# Câu này làm khá dài và có tính chất tổng hợp\n",
        "cleanSen = cleanSentences(input_sentence)\n",
        "split = cleanSen.split()\n",
        "zero_ = np.zeros((1,maxSeqLength),dtype = 'int32')\n",
        "index = 0\n",
        "for _ in split:\n",
        "    try:\n",
        "        zero_[0][index] = wordsList.index(_)\n",
        "    except:\n",
        "        zero_[0][index] = wordsList.index('UNK')\n",
        "    index +=1\n",
        "    if index >= 180:\n",
        "        break\n",
        "\n",
        "inputData = tf.placeholder(tf.int32,[1, maxSeqLength])\n",
        "\n",
        "data  = tf.nn.embedding_lookup(wordVectors, inputData)\n",
        "\n",
        "init_state = lstmLayers.zero_state(1, tf.float32)\n",
        "\n",
        "value,_ = tf.nn.dynamic_rnn(lstmLayers, data, dtype=tf.float32, initial_state=initial_state)\n",
        "\n",
        "last = tf.gather(value, int(value.get_shape()[2]-1))\n",
        "\n",
        "prediction = (tf.matmul(last, weight)+bias)\n",
        "\n",
        "label = tf.argmax(prediction, 1)\n",
        "\n",
        "print(labels[sess.run(label, {inputData: zero_})[0]])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "ZLDhCvxJKjw7"
      },
      "source": [
        "# Kết luận"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtnBpzxXKjw7"
      },
      "source": [
        "Như vậy qua bài tập này, các bạn được ôn lại mô hình Word2Vec và sử dụng mô hình này để biểu diễn cho một văn bản. Sử dụng cách biểu diễn này để đưa vào mô hình RNN với nhiều đơn vị LSTM. Các bạn có thể thử nghiệm trên các cấu hình khác nhau bằng cách thay đổi các hyperparameter."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PwXLNoCWKjws",
        "bYGzb9j9Kjwu"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}