{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lê Nguyễn Minh Huy - 20521394"
      ],
      "metadata": {
        "id": "jSQgImT_TAx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Explore interesting properties of the word vectors with GenSim \n"
      ],
      "metadata": {
        "id": "Idxk_6soQhZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import gensim"
      ],
      "metadata": {
        "id": "Ns1Di4wLQmVm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VREwa-EjQdAc"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the pretrained model"
      ],
      "metadata": {
        "id": "4_iT7ek0QrlR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "# Unzip the model\n",
        "!unzip wiki-news-300d-1M.vec.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swGNo8DjQtAS",
        "outputId": "781e8d0b-688e-4316-8103-c1a58c53a88b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-15 15:48:44--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  30.2MB/s    in 19s     \n",
            "\n",
            "2022-11-15 15:49:04 (33.5 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('wiki-news-300d-1M.vec', binary=False)"
      ],
      "metadata": {
        "id": "2fVnrWZVQyr-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try the very first step: trying to represent a token by a feature vector.\n",
        "\n",
        "For example, we use the following syntax to map the word `'king'` to a 300-dimensonal vector:"
      ],
      "metadata": {
        "id": "1qrnWZe_Q5st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "king = model['king']\n",
        "print(king)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lo-YWu8Q6R3",
        "outputId": "bb483d23-b3c8-4075-a96d-2d99980153c8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.082e-01  4.450e-02 -3.840e-02  1.100e-03 -8.880e-02  7.130e-02\n",
            " -6.960e-02 -4.770e-02  7.100e-03 -4.080e-02 -7.070e-02 -2.660e-02\n",
            "  5.000e-02 -8.240e-02  8.480e-02 -1.627e-01 -8.510e-02 -2.950e-02\n",
            "  1.534e-01 -1.828e-01 -2.208e-01  2.430e-02 -9.210e-02 -1.089e-01\n",
            " -1.009e-01 -1.190e-02  3.770e-02  2.038e-01  7.200e-02  2.020e-02\n",
            "  2.798e-01  1.150e-02 -1.510e-02  1.037e-01  4.000e-04 -1.040e-02\n",
            "  1.960e-02  1.265e-01  8.280e-02 -1.369e-01  1.070e-01  1.270e-01\n",
            " -3.490e-02 -6.830e-02 -1.140e-02  3.370e-02  1.260e-02  7.920e-02\n",
            "  4.400e-02 -2.530e-02  4.890e-02 -7.850e-02 -6.259e-01 -9.720e-02\n",
            "  1.654e-01 -5.780e-02 -4.370e-02  4.090e-02 -1.820e-02 -1.891e-01\n",
            "  2.770e-02 -1.460e-02 -5.310e-02  4.260e-02  4.900e-03  4.000e-03\n",
            "  1.423e-01 -9.750e-02 -3.500e-03  9.630e-02 -1.900e-03 -1.466e-01\n",
            " -1.662e-01  6.650e-02 -1.500e-01 -1.267e-01  2.670e-02 -1.560e-01\n",
            " -1.442e-01  1.515e-01  2.420e-02 -6.080e-02  9.180e-02 -2.407e-01\n",
            " -4.110e-02 -1.420e-02  6.550e-02 -3.590e-02  1.459e-01  9.400e-02\n",
            "  1.590e-02  6.380e-02 -1.077e-01 -5.170e-02 -1.370e-02  5.120e-02\n",
            " -2.750e-02 -5.070e-02  6.900e-03  3.660e-02 -1.529e-01 -1.813e-01\n",
            "  3.390e-02 -8.510e-02 -5.400e-02  1.180e-01  1.039e-01  6.190e-02\n",
            " -2.350e-02 -1.150e-02  1.648e-01  9.360e-02 -5.000e-03 -9.790e-02\n",
            " -5.890e-02 -7.210e-02 -1.586e-01  2.270e-02 -4.460e-02 -3.398e-01\n",
            " -2.840e-02 -2.507e-01  4.510e-02 -1.226e-01  8.000e-02  2.365e-01\n",
            "  7.560e-02 -8.530e-02  1.157e-01  2.780e-02  7.100e-02 -1.314e-01\n",
            " -4.630e-02  4.270e-02 -5.050e-02 -2.490e-02  1.182e-01  4.810e-02\n",
            " -1.085e-01 -1.600e-02  3.900e-03 -3.860e-02  1.551e-01  2.695e-01\n",
            "  7.070e-02 -8.420e-02  1.167e-01  8.450e-02 -1.040e-02  2.060e-02\n",
            "  4.690e-02  5.700e-03  8.970e-02  7.230e-02  2.220e-02  7.270e-02\n",
            "  6.420e-02 -2.350e-02 -2.160e-02 -6.010e-02  5.370e-02 -2.842e-01\n",
            " -1.047e-01  1.733e-01  2.100e-03 -1.050e-02  1.143e-01  2.150e-02\n",
            "  7.400e-03 -5.040e-02 -4.900e-03  1.190e-02 -2.700e-02  1.450e-02\n",
            "  9.670e-02  9.030e-02  3.145e-01  1.222e-01  9.850e-02  2.126e-01\n",
            " -1.030e-01  7.930e-02 -7.870e-02 -5.930e-02  7.390e-02 -6.960e-02\n",
            " -8.180e-02  3.200e-02 -1.808e-01  4.770e-02  8.250e-02 -1.270e-02\n",
            "  1.445e-01 -6.050e-02 -5.130e-02  9.450e-02 -1.030e-01  4.750e-02\n",
            "  9.820e-02  2.402e-01  8.600e-03 -2.410e-02 -3.320e-02  4.300e-02\n",
            " -4.170e-02  1.990e-02 -5.280e-02 -6.300e-02  3.470e-02  5.800e-02\n",
            " -2.600e-02  1.113e-01  9.890e-02 -3.800e-03 -1.272e-01 -9.790e-02\n",
            "  4.500e-03  6.100e-03 -3.980e-02 -8.500e-03 -3.500e-03 -1.191e-01\n",
            " -9.490e-02  1.230e-02  1.705e-01 -2.065e-01  5.500e-02  4.530e-02\n",
            "  4.240e-02 -5.780e-02 -3.480e-02 -1.770e-02  3.437e-01 -6.590e-02\n",
            "  9.240e-02 -1.122e-01 -1.588e-01  1.068e-01 -3.029e-01  1.800e-03\n",
            "  3.170e-02  1.857e-01  3.600e-02  8.290e-02  2.240e-02  9.340e-02\n",
            " -4.750e-02  1.719e-01  1.500e-03  4.849e-01 -2.280e-02 -9.020e-02\n",
            "  4.650e-02 -1.087e-01  1.374e-01  1.150e-02 -1.246e-01  5.090e-02\n",
            "  1.578e-01 -1.667e-01 -3.400e-02  4.690e-02  5.680e-02  1.599e-01\n",
            " -3.915e-01  3.560e-02  2.870e-02 -2.275e-01 -1.378e-01 -2.650e-02\n",
            " -1.115e-01  1.804e-01  7.960e-02 -9.870e-02  9.050e-02  3.556e-01\n",
            "  2.400e-02  2.460e-02  2.830e-02  6.090e-02 -2.270e-02 -4.690e-02\n",
            " -5.350e-02  4.400e-02  1.021e-01 -1.398e-01  5.370e-02 -2.549e-01\n",
            "  8.270e-02 -1.011e-01  4.700e-03 -7.120e-02  1.442e-01 -7.000e-02\n",
            "  1.230e-02  3.440e-02 -5.700e-02  1.580e-02  5.440e-02  2.560e-02]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use that feature vector compute the similarity with other words."
      ],
      "metadata": {
        "id": "fR7qgow4RDzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "car = model['car']\n",
        "queen = model['queen']\n",
        "power = model['power']\n",
        "\n",
        "print('queen and king: ', queen.dot(king))\n",
        "print('power and king: ', power.dot(king))\n",
        "print('car and king: ', car.dot(king))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcuO_uNvQ9jE",
        "outputId": "0fe3c3f2-69c5-4d1d-d947-f4a40d23f0fb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "queen and king:  3.2907822\n",
            "power and king:  1.6147376\n",
            "car and king:  1.4670291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "like = model['like']\n",
        "love = model['love']\n",
        "hate = model['hate']\n",
        "\n",
        "print('love and like: ', love.dot(like))\n",
        "print('like and hate: ', like.dot(hate))\n",
        "print('love and hate: ', love.dot(hate))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNFIm8zrRIl3",
        "outputId": "96cb6894-149a-4ddd-f944-ad08da44a24e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "love and like:  1.6091172\n",
            "like and hate:  1.8135115\n",
            "love and hate:  2.8157127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linguistic regularities"
      ],
      "metadata": {
        "id": "PmrU87xfRV1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# king - man + woman = queen\n",
        "print(model.most_similar(positive=['woman', 'king'], negative=['man']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNrAv0O8RMtX",
        "outputId": "1e5baf02-ea00-4938-e7da-9700c59814cd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7515910863876343), ('monarch', 0.6741327047348022), ('princess', 0.6713887453079224), ('kings', 0.6698989868164062), ('kingdom', 0.5971318483352661), ('royal', 0.5921063423156738), ('uncrowned', 0.5911505818367004), ('prince', 0.5909028053283691), ('lady', 0.5904011130332947), ('monarchs', 0.5884358286857605)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# queen + man - king = woman\n",
        "result = model.most_similar(positive=['queen', 'man'], negative=['king'])\n",
        "print(\"If the king is a man than the queen is:\", result[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bvj2VKLGRXFd",
        "outputId": "afb71580-c1b1-4d75-db05-ffa304ab33f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If the king is a man than the queen is: woman\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Another relations"
      ],
      "metadata": {
        "id": "abaWtnLLR3VC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Word2vec with Tensorflow"
      ],
      "metadata": {
        "id": "R8-TmaV9SraS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# capital - country\n",
        "capital = model.most_similar([\"Paris\", \"Britain\"], [\"France\"], topn=1)\n",
        "print(\"If Paris is capital of France, capital of Britain is:\", capital)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8OyE5TP8AtS",
        "outputId": "61b848de-6b2f-4f5b-ec1c-49e918cb7c5e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Capital of Britain is: [('London', 0.7543942928314209)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# noun - plural noun\n",
        "plural = model.most_similar([\"pens\", \"apple\"], [\"pen\"], topn=1)\n",
        "print(\"If pens is plural noun of pen, plural noun of apple is:\", plural)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zC6FL-mz8AnV",
        "outputId": "fa17ca91-fe13-4c3c-e831-50441c643225"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If pens is plural noun of pen, plural noun of apple is: [('apples', 0.7407915592193604)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# verb - v3 form\n",
        "v3 = model.most_similar([\"attended\", \"play\"], [\"attend\"], topn=1)\n",
        "print(\"If attended is v3 of attend, v3 of play is:\", v3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJeIZPNk8Ajv",
        "outputId": "5a7d7b4b-7ecd-47dc-fab2-80dd7878ca48"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If attended is v3 of attend, v3 of play is: [('played', 0.7761051654815674)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### import model"
      ],
      "metadata": {
        "id": "pwM620MfSt59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\")\n"
      ],
      "metadata": {
        "id": "Oi69JrTDSvUu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "love_vec = embed([\"love\"]).numpy()\n",
        "like_vec = embed([\"like\"]).numpy()\n",
        "hate_vec = embed([\"hate\"]).numpy()"
      ],
      "metadata": {
        "id": "i_yGdoyVS3CH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "love_vec.dot(like_vec.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ZaGwUfS53r",
        "outputId": "9636b856-ceaa-4899-f0cb-4283b18844d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24091528]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "love_vec.dot(hate_vec.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vllHS9IUS7ly",
        "outputId": "85ab48bb-395f-418a-8d56-3dce8880caaf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5915959]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}